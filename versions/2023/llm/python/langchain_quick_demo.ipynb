{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "129d7c07",
   "metadata": {},
   "source": [
    "### LangChain and OpenAI LLM Quick Demo\n",
    "\n",
    "This demo showcases how to use LangChain to build useful large language model applications. LangChain is a framework that allows us to interact with Large Language Models (LLMs) like OpenAI GPTs.\n",
    "\n",
    "First, install the required modules.\n",
    "\n",
    "Always best to upgrade since `langchain` is rapidliy developing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bc9a593b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (0.0.135)\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.0.136-py3-none-any.whl (515 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m515.4/515.4 kB\u001b[0m \u001b[31m498.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from langchain) (4.0.2)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from langchain) (0.5.7)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from langchain) (1.23.5)\n",
      "Requirement already satisfied: pydantic<2,>=1 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from langchain) (1.10.6)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from langchain) (2.28.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from langchain) (3.8.4)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from langchain) (1.2.4)\n",
      "Requirement already satisfied: SQLAlchemy<2,>=1 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from langchain) (1.4.47)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.2)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.1.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.8.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from pydantic<2,>=1->langchain) (4.5.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2022.12.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from SQLAlchemy<2,>=1->langchain) (2.0.2)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
      "Installing collected packages: langchain\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.0.135\n",
      "    Uninstalling langchain-0.0.135:\n",
      "      Successfully uninstalled langchain-0.0.135\n",
      "Successfully installed langchain-0.0.136\n",
      "Requirement already satisfied: openai in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (0.27.4)\n",
      "Requirement already satisfied: tqdm in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: requests>=2.20 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from openai) (2.28.2)\n",
      "Requirement already satisfied: aiohttp in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from openai) (3.8.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from requests>=2.20->openai) (1.26.15)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from requests>=2.20->openai) (3.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from requests>=2.20->openai) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from aiohttp->openai) (22.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from aiohttp->openai) (1.8.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from aiohttp->openai) (6.0.4)\n"
     ]
    }
   ],
   "source": [
    "! pip install langchain --upgrade\n",
    "! pip install openai --upgrade"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "834aba87",
   "metadata": {},
   "source": [
    "Then, import the packages to use.\n",
    "\n",
    "Please create your [OpenAI](https://openai.com/) key before proceeding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b88d9429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import textwrap\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "query = input(\"OpenAI key: \")\n",
    "os.environ[\"OPENAI_API_KEY\"] = query"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0923bdaa",
   "metadata": {},
   "source": [
    "#### Demo 1: A Simple Question and Answering Example\n",
    "\n",
    "The simplest example is a question and answering application. To build the demo, execute the following: \n",
    "\n",
    "- Load OpenAI Large Language Model (`llm`). Temperature is a measure of uncertainty or randomness of answers. Higher temperature means more randomness. In other words, temp = 0 means the model will always give the same answer. Temp = 1 means the model will give answers with more variance. Let's set it to 0.5.\n",
    "- Provide a text query\n",
    "- Request the Large Language Model to process the query\n",
    "- Print the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4fccf101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Paris, France\n",
      "2. Rome, Italy\n",
      "3. London, England\n",
      "4. New York City, USA\n",
      "5. Barcelona, Spain\n",
      "6. Tokyo, Japan\n",
      "7. Amsterdam, Netherlands\n",
      "8. Bangkok, Thailand\n",
      "9. Istanbul, Turkey\n",
      "10. Rio de Janeiro, Brazil\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAI(temperature=0.5)\n",
    "text = \"What are the 10 best places to visit?\"\n",
    "print(llm(text))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "002a8718",
   "metadata": {},
   "source": [
    "#### Demo 2: Using a Prompt Template\n",
    "\n",
    "A meaningful interaction with a LLM requires a good prompt to elicit a good answer. In this example a prompt template is provided to elicit a good answer from the LLM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d49eaed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatted prompt: What are the 10 best places to eat?\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"to_do_what\"],\n",
    "    template=\"What are the 10 best places to {to_do_what}?\",\n",
    ")\n",
    "formatted_prompt = prompt.format(to_do_what=\"eat\")\n",
    "print(f\"Formatted prompt: {formatted_prompt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfe7850",
   "metadata": {},
   "source": [
    "#### Demo 3: A Simple Chain\n",
    "\n",
    "LLM is not very useful unless we can interact with it using prompt. In the same way, a prompt is not valuable unless we can use it to interact with a LLM. A chain puts them together. Below is a simple chain.\n",
    "\n",
    "Chain: Prompt &rarr; LLM \n",
    "\n",
    "Then, the chain can now be queried.\n",
    "\n",
    "`chain.run(<to_do_what>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9b1bcffe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: What are the 10 best places to eat street food?\n",
      "AI: \n",
      "\n",
      "\n",
      "1. Bangkok, Thailand\n",
      "2. Istanbul, Turkey\n",
      "3. Mexico City, Mexico\n",
      "4. Penang, Malaysia\n",
      "5. Hoi An, Vietnam\n",
      "6. New Delhi, India\n",
      "7. Hong Kong\n",
      "8. Marrakesh, Morocco\n",
      "9. Tokyo, Japan\n",
      "10. Seoul, South Korea\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "formatted_prompt = prompt.format(to_do_what=\"...\")\n",
    "query = input(formatted_prompt)\n",
    "formatted_prompt = prompt.format(to_do_what=query)\n",
    "print(f\"Human: {formatted_prompt}\")\n",
    "results = chain.run(query).split('\\n')\n",
    "print(f\"AI: \")\n",
    "for result in results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172cb57a",
   "metadata": {},
   "source": [
    "#### Demo 4: Enabling Long-Term Memory \n",
    "\n",
    "A conversation has context. Sometimes, the context has a reference to a discussion long time ago. Without the ability to remember something said a while back, the conversation can easily become frustrating. Thus, memory is important. In this example, a memory is incorporated in the chain.\n",
    "\n",
    "Below is a conversation with context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a0d58984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Hi there! My name is AI-01. It's nice to meet you. How can I help you today?\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import OpenAI, ConversationChain\n",
    "\n",
    "llm = OpenAI(temperature=0.5)\n",
    "conversation = ConversationChain(llm=llm)\n",
    "\n",
    "conversation.predict(input=\"Hi! I want to talk to you. What is your name?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cfc05376",
   "metadata": {},
   "source": [
    "##### Let's Build a Conversation Chain\n",
    "\n",
    "The human can ask questions all about a topic. Assume that there is context in the conversation. To end the conversation, the human can say \"bye\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "33219880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: : I want to travel the world. I want to go to southeast asia. please help\n",
      "me prepare travel plans.\n",
      "AI:  Absolutely! Southeast Asia is a great place to visit. What kind of places\n",
      "are you interested in seeing in Southeast Asia? Are you looking for cities,\n",
      "beaches, mountains, or something else?\n",
      "Human: : beaches\n",
      "AI:   Got it. Let me see what I can find for you. I'm sure I can come up with\n",
      "some great beach destinations with plenty of activities. Give me a few minutes\n",
      "to compile some ideas and I'll get back to you shortly.\n",
      "Human: : do you have anything in mind\n",
      "AI:    Absolutely! I've compiled a few ideas for you. Here are some of the top\n",
      "beach destinations in Southeast Asia that I recommend: Boracay in the\n",
      "Philippines, Koh Samui in Thailand, Tanjung Aru Beach in Malaysia, and Nusa Dua\n",
      "in Indonesia. Do any of these sound like places you'd like to visit?\n",
      "Human: : i heard boracay is great\n",
      "AI:    Yes, Boracay is a wonderful destination. I can help you plan out your\n",
      "itinerary and book any necessary accommodations and transportation. Just let me\n",
      "know what you need and I'll take care of it.\n",
      "Human: : i am coming from london.\n",
      "AI:     Got it. You can get to Boracay from London by taking a flight to Manila,\n",
      "Philippines, followed by a domestic flight to Caticlan Airport. From there, you\n",
      "can take a boat to Boracay Island. I can help you book your flights and boat\n",
      "tickets if you'd like.\n",
      "Human: : what about accommodations\n",
      "AI:  Absolutely! There are plenty of accommodation options in Boracay. You can\n",
      "choose from resorts, hotels, hostels, and more. Depending on your budget and\n",
      "preferences, I can help you find the perfect place to stay.\n",
      "Human: : hotels\n",
      "AI:   Got it. There are plenty of hotels in Boracay. I can help you find one\n",
      "that fits your budget and preferences. Just let me know what you're looking for\n",
      "and I'll take care of it.\n",
      "AI: Bye!\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    input_prompt = \"Human: \"\n",
    "    query = input(input_prompt)\n",
    "\n",
    "    if query.lower() == \"bye\":\n",
    "        print(\"AI: Bye!\")\n",
    "        break\n",
    "\n",
    "    text = f\"{input_prompt}: {query}\"\n",
    "    print(textwrap.fill(text, width=80))\n",
    "    text = f\"AI: {conversation.predict(input=query)}\"\n",
    "    print(textwrap.fill(text, width=80))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3d50d4f4",
   "metadata": {},
   "source": [
    "#### Demo 5: Using Agent and Tools to Determine what Actions to Take to Solve a Problem\n",
    "\n",
    "Sometimes, a problem can not be solved in one step. Additional tools may also needed in order to solve the problem. In this demo, the LLM uses an agent to determine what actions to take and what tools to use.\n",
    "\n",
    "The focus is on math problems. `llm-math` tool is used. More info about [tools](https://langchain.readthedocs.io/en/latest/modules/agents/tools.html) and [agents](https://langchain.readthedocs.io/en/latest/modules/agents/agents.html) are available in the LangChain documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e62e892c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5dea1639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to figure out how many oranges are in the basket\n",
      "Action: Calculator\n",
      "Action Input: 10 - 5 + 8\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 13\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: There are 13 oranges in the basket.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'There are 13 oranges in the basket.'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, let's load the language model we're going to use to control the agent.\n",
    "llm = OpenAI(temperature=0.0)\n",
    "\n",
    "# Next, let's load some tools to use. \n",
    "# Note that the `llm-math` tool uses an LLM, so we need to pass that in.\n",
    "tools = load_tools([\"llm-math\"], llm=llm)\n",
    "\n",
    "# Finally, let's initialize an agent with the tools, the language model, \n",
    "# and the type of agent we want to use.\n",
    "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)\n",
    "\n",
    "# Now let's test it out!\n",
    "\n",
    "query = input(\"Human: \")\n",
    "text = f\"Human: {query}\"\n",
    "agent.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b9713d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "82ad6d7bc5c4d1338129f53582d686f501ccbc16afd0f50ed25b05b303292daa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
