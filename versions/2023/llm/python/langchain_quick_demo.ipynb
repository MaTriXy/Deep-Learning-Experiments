{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "129d7c07",
   "metadata": {},
   "source": [
    "### LangChain and OpenAI LLM Quick Demo\n",
    "\n",
    "This demo showcases how to use LangChain to build useful large language model applications. LangChain is a framework that allows us to interact with Large Language Models (LLMs) like OpenAI GPTs.\n",
    "\n",
    "First, install the required modules.\n",
    "\n",
    "Always best to upgrade since `langchain` is rapidliy developing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc9a593b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (0.0.156)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.3 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from langchain) (1.4.47)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from langchain) (0.5.7)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from langchain) (2.28.2)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from langchain) (1.2.4)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from langchain) (2.8.4)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from langchain) (4.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from langchain) (3.8.4)\n",
      "Requirement already satisfied: pydantic<2,>=1 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from langchain) (1.10.6)\n",
      "Requirement already satisfied: tqdm>=4.48.0 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from langchain) (4.65.0)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from langchain) (1.23.5)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.2)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.8.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from pydantic<2,>=1->langchain) (4.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.3->langchain) (2.0.2)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: openai in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (0.27.6)\n",
      "Requirement already satisfied: aiohttp in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from openai) (3.8.4)\n",
      "Requirement already satisfied: requests>=2.20 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from openai) (2.28.2)\n",
      "Requirement already satisfied: tqdm in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from requests>=2.20->openai) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from requests>=2.20->openai) (3.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from requests>=2.20->openai) (1.26.15)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from aiohttp->openai) (22.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (from aiohttp->openai) (1.8.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install langchain --upgrade\n",
    "! pip install openai --upgrade"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "834aba87",
   "metadata": {},
   "source": [
    "Then, import the packages to use.\n",
    "\n",
    "Please create your [OpenAI](https://openai.com/) key before proceeding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b88d9429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import textwrap\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "query = input(\"OpenAI key: \")\n",
    "os.environ[\"OPENAI_API_KEY\"] = query"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0923bdaa",
   "metadata": {},
   "source": [
    "#### Demo 1: A Simple Question and Answering Example\n",
    "\n",
    "The simplest example is a question and answering application. To build the demo, execute the following: \n",
    "\n",
    "- Load OpenAI Large Language Model (`llm`). Temperature is a measure of uncertainty or randomness of answers. Higher temperature means more randomness. In other words, temp = 0 means the model will always give the same answer. Temp = 1 means the model will give answers with more variance. Let's set it to 0.5.\n",
    "- Provide a text query\n",
    "- Request the Large Language Model to process the query\n",
    "- Print the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fccf101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Paris, France\n",
      "2. London, England\n",
      "3. Rome, Italy\n",
      "4. New York City, USA\n",
      "5. Barcelona, Spain\n",
      "6. Tokyo, Japan\n",
      "7. Amsterdam, Netherlands\n",
      "8. Prague, Czech Republic\n",
      "9. Istanbul, Turkey\n",
      "10. Hong Kong, China\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAI(temperature=0.5)\n",
    "text = \"What are the 10 best places to visit?\"\n",
    "print(llm(text))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "002a8718",
   "metadata": {},
   "source": [
    "#### Demo 2: Using a Prompt Template\n",
    "\n",
    "A meaningful interaction with a LLM requires a good prompt to elicit a good answer. In this example a prompt template is provided to elicit a good answer from the LLM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d49eaed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatted prompt: What are the 10 best places to eat?\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"to_do_what\"],\n",
    "    template=\"What are the 10 best places to {to_do_what}?\",\n",
    ")\n",
    "formatted_prompt = prompt.format(to_do_what=\"eat\")\n",
    "print(f\"Formatted prompt: {formatted_prompt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfe7850",
   "metadata": {},
   "source": [
    "#### Demo 3: A Simple Chain\n",
    "\n",
    "LLM is not very useful unless we can interact with it using prompt. In the same way, a prompt is not valuable unless we can use it to interact with a LLM. A chain puts them together. Below is a simple chain.\n",
    "\n",
    "Chain: Prompt &rarr; LLM \n",
    "\n",
    "Then, the chain can now be queried.\n",
    "\n",
    "`chain.run(<to_do_what>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b1bcffe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: What are the 10 best places to to eat street food?\n",
      "AI: \n",
      "\n",
      "\n",
      "1. La Boqueria Market, Barcelona, Spain\n",
      "2. Khao San Road, Bangkok, Thailand\n",
      "3. Chiang Mai Night Bazaar, Thailand\n",
      "4. Tsukiji Fish Market, Tokyo, Japan\n",
      "5. La Rambla, Barcelona, Spain\n",
      "6. La Boca, Buenos Aires, Argentina\n",
      "7. Old Delhi, India\n",
      "8. St. Lawrence Market, Toronto, Canada\n",
      "9. La Paz, Bolivia\n",
      "10. Georgetown, Penang, Malaysia\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "formatted_prompt = prompt.format(to_do_what=\"...\")\n",
    "query = input(formatted_prompt)\n",
    "formatted_prompt = prompt.format(to_do_what=query)\n",
    "print(f\"Human: {formatted_prompt}\")\n",
    "results = chain.run(query).split('\\n')\n",
    "print(f\"AI: \")\n",
    "for result in results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172cb57a",
   "metadata": {},
   "source": [
    "#### Demo 4: Enabling Long-Term Memory \n",
    "\n",
    "A conversation has context. Sometimes, the context has a reference to a discussion long time ago. Without the ability to remember something said a while back, the conversation can easily become frustrating. Thus, memory is important. In this example, a memory is incorporated in the chain.\n",
    "\n",
    "Below is a conversation with context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0d58984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi! I want to talk to you. What is your name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Hi there! My name is AI-Bot. It's nice to meet you. What would you like to talk about?\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import OpenAI, ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "llm = OpenAI(temperature=0.5)\n",
    "# we use a memory to store the conversation history\n",
    "memory = ConversationBufferMemory() \n",
    "conversation = ConversationChain(\n",
    "        llm=llm, \n",
    "        verbose=True, \n",
    "        memory=memory\n",
    "        )\n",
    "\n",
    "conversation.predict(input=\"Hi! I want to talk to you. What is your name?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cfc05376",
   "metadata": {},
   "source": [
    "##### Let's Build a Conversation Chain\n",
    "\n",
    "The human can ask questions all about a topic. Assume that there is context in the conversation. To end the conversation, the human can say \"bye\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33219880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: : I want to learn about AI. Where do I start?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi! I want to talk to you. What is your name?\n",
      "AI:  Hi there! My name is AI-Bot. It's nice to meet you. What would you like to talk about?\n",
      "Human: I want to learn about AI. Where do I start?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "AI:  Great question! You can start by learning about the basics of AI and its\n",
      "history. AI has been around for decades, but has become increasingly popular in\n",
      "recent years. There are many resources available online that can help you get\n",
      "started.\n",
      "Human: : What is the cheapest and quickest way to master AI?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi! I want to talk to you. What is your name?\n",
      "AI:  Hi there! My name is AI-Bot. It's nice to meet you. What would you like to talk about?\n",
      "Human: I want to learn about AI. Where do I start?\n",
      "AI:  Great question! You can start by learning about the basics of AI and its history. AI has been around for decades, but has become increasingly popular in recent years. There are many resources available online that can help you get started.\n",
      "Human: What is the cheapest and quickest way to master AI?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "AI:  Unfortunately, there is no single answer to that question as it depends on\n",
      "your goals and resources. Depending on your individual needs, there are a\n",
      "variety of options available. For example, you could attend an online course,\n",
      "read books, or watch tutorials. You could also join a community of AI\n",
      "enthusiasts, where you can ask questions and get advice from experienced\n",
      "professionals.\n",
      "AI: Bye!\n",
      "messages=[HumanMessage(content='Hi! I want to talk to you. What is your name?', additional_kwargs={}, example=False), AIMessage(content=\" Hi there! My name is AI-Bot. It's nice to meet you. What would you like to talk about?\", additional_kwargs={}, example=False), HumanMessage(content='I want to learn about AI. Where do I start?', additional_kwargs={}, example=False), AIMessage(content=' Great question! You can start by learning about the basics of AI and its history. AI has been around for decades, but has become increasingly popular in recent years. There are many resources available online that can help you get started.', additional_kwargs={}, example=False), HumanMessage(content='What is the cheapest and quickest way to master AI?', additional_kwargs={}, example=False), AIMessage(content=' Unfortunately, there is no single answer to that question as it depends on your goals and resources. Depending on your individual needs, there are a variety of options available. For example, you could attend an online course, read books, or watch tutorials. You could also join a community of AI enthusiasts, where you can ask questions and get advice from experienced professionals.', additional_kwargs={}, example=False)]\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    input_prompt = \"Human: \"\n",
    "    query = input(input_prompt)\n",
    "\n",
    "    if query.lower() == \"bye\":\n",
    "        print(\"AI: Bye!\")\n",
    "        # print the conversation history\n",
    "        print(memory.chat_memory)\n",
    "        break\n",
    "\n",
    "    text = f\"{input_prompt}: {query}\"\n",
    "    print(textwrap.fill(text, width=80))\n",
    "    text = f\"AI: {conversation.predict(input=query)}\"\n",
    "    print(textwrap.fill(text, width=80))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3d50d4f4",
   "metadata": {},
   "source": [
    "#### Demo 5: Using Agent and Tools to Determine what Actions to Take to Solve a Problem\n",
    "\n",
    "Sometimes, a problem can not be solved in one step. Additional tools may also needed in order to solve the problem. In this demo, the LLM uses an agent to determine what actions to take and what tools to use.\n",
    "\n",
    "The focus is on math problems. `llm-math` tool is used. More info about [tools](https://langchain.readthedocs.io/en/latest/modules/agents/tools.html) and [agents](https://langchain.readthedocs.io/en/latest/modules/agents/agents.html) are available in the LangChain documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e62e892c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5dea1639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find a prime number\n",
      "Action: Calculator\n",
      "Action Input: List of prime numbers less than 50\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 328\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to find the smallest prime number\n",
      "Action: Calculator\n",
      "Action Input: Sort the list of prime numbers in ascending order\u001b[0m"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'VariableNode' object has no attribute 'sort'. Please try again with a valid numerical expression",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/llm/lib/python3.10/site-packages/langchain/chains/llm_math/base.py:80\u001b[0m, in \u001b[0;36mLLMMathChain._evaluate_expression\u001b[0;34m(self, expression)\u001b[0m\n\u001b[1;32m     78\u001b[0m     local_dict \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mpi\u001b[39m\u001b[39m\"\u001b[39m: math\u001b[39m.\u001b[39mpi, \u001b[39m\"\u001b[39m\u001b[39me\u001b[39m\u001b[39m\"\u001b[39m: math\u001b[39m.\u001b[39me}\n\u001b[1;32m     79\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\n\u001b[0;32m---> 80\u001b[0m         numexpr\u001b[39m.\u001b[39;49mevaluate(\n\u001b[1;32m     81\u001b[0m             expression\u001b[39m.\u001b[39;49mstrip(),\n\u001b[1;32m     82\u001b[0m             global_dict\u001b[39m=\u001b[39;49m{},  \u001b[39m# restrict access to globals\u001b[39;49;00m\n\u001b[1;32m     83\u001b[0m             local_dict\u001b[39m=\u001b[39;49mlocal_dict,  \u001b[39m# add common mathematical functions\u001b[39;49;00m\n\u001b[1;32m     84\u001b[0m         )\n\u001b[1;32m     85\u001b[0m     )\n\u001b[1;32m     86\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/llm/lib/python3.10/site-packages/numexpr/necompiler.py:817\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(ex, local_dict, global_dict, out, order, casting, **kwargs)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[39mif\u001b[39;00m expr_key \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m _names_cache:\n\u001b[0;32m--> 817\u001b[0m     _names_cache[expr_key] \u001b[39m=\u001b[39m getExprNames(ex, context)\n\u001b[1;32m    818\u001b[0m names, ex_uses_vml \u001b[39m=\u001b[39m _names_cache[expr_key]\n",
      "File \u001b[0;32m~/anaconda3/envs/llm/lib/python3.10/site-packages/numexpr/necompiler.py:704\u001b[0m, in \u001b[0;36mgetExprNames\u001b[0;34m(text, context)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgetExprNames\u001b[39m(text, context):\n\u001b[0;32m--> 704\u001b[0m     ex \u001b[39m=\u001b[39m stringToExpression(text, {}, context)\n\u001b[1;32m    705\u001b[0m     ast \u001b[39m=\u001b[39m expressionToAST(ex)\n",
      "File \u001b[0;32m~/anaconda3/envs/llm/lib/python3.10/site-packages/numexpr/necompiler.py:289\u001b[0m, in \u001b[0;36mstringToExpression\u001b[0;34m(s, types, context)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[39m# now build the expression\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m ex \u001b[39m=\u001b[39m \u001b[39meval\u001b[39;49m(c, names)\n\u001b[1;32m    290\u001b[0m \u001b[39mif\u001b[39;00m expressions\u001b[39m.\u001b[39misConstant(ex):\n",
      "File \u001b[0;32m<expr>:1\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'VariableNode' object has no attribute 'sort'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m query \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mHuman: \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m text \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mHuman: \u001b[39m\u001b[39m{\u001b[39;00mquery\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 16\u001b[0m agent\u001b[39m.\u001b[39;49mrun(query)\n",
      "File \u001b[0;32m~/anaconda3/envs/llm/lib/python3.10/site-packages/langchain/chains/base.py:238\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, callbacks, *args, **kwargs)\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    237\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`run` supports only one positional argument.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 238\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(args[\u001b[39m0\u001b[39;49m], callbacks\u001b[39m=\u001b[39;49mcallbacks)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys[\u001b[39m0\u001b[39m]]\n\u001b[1;32m    240\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[1;32m    241\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(kwargs, callbacks\u001b[39m=\u001b[39mcallbacks)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys[\u001b[39m0\u001b[39m]]\n",
      "File \u001b[0;32m~/anaconda3/envs/llm/lib/python3.10/site-packages/langchain/chains/base.py:142\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    141\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 142\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    143\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    144\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(inputs, outputs, return_only_outputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/llm/lib/python3.10/site-packages/langchain/chains/base.py:136\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks)\u001b[0m\n\u001b[1;32m    130\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[1;32m    131\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m},\n\u001b[1;32m    132\u001b[0m     inputs,\n\u001b[1;32m    133\u001b[0m )\n\u001b[1;32m    134\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    135\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 136\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m    137\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    138\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[1;32m    139\u001b[0m     )\n\u001b[1;32m    140\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    141\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/anaconda3/envs/llm/lib/python3.10/site-packages/langchain/agents/agent.py:904\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    902\u001b[0m \u001b[39m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[1;32m    903\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[0;32m--> 904\u001b[0m     next_step_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_take_next_step(\n\u001b[1;32m    905\u001b[0m         name_to_tool_map,\n\u001b[1;32m    906\u001b[0m         color_mapping,\n\u001b[1;32m    907\u001b[0m         inputs,\n\u001b[1;32m    908\u001b[0m         intermediate_steps,\n\u001b[1;32m    909\u001b[0m         run_manager\u001b[39m=\u001b[39;49mrun_manager,\n\u001b[1;32m    910\u001b[0m     )\n\u001b[1;32m    911\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[1;32m    912\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_return(\n\u001b[1;32m    913\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[39m=\u001b[39mrun_manager\n\u001b[1;32m    914\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/llm/lib/python3.10/site-packages/langchain/agents/agent.py:782\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m    780\u001b[0m         tool_run_kwargs[\u001b[39m\"\u001b[39m\u001b[39mllm_prefix\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    781\u001b[0m     \u001b[39m# We then call the tool on the tool input to get an observation\u001b[39;00m\n\u001b[0;32m--> 782\u001b[0m     observation \u001b[39m=\u001b[39m tool\u001b[39m.\u001b[39;49mrun(\n\u001b[1;32m    783\u001b[0m         agent_action\u001b[39m.\u001b[39;49mtool_input,\n\u001b[1;32m    784\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    785\u001b[0m         color\u001b[39m=\u001b[39;49mcolor,\n\u001b[1;32m    786\u001b[0m         callbacks\u001b[39m=\u001b[39;49mrun_manager\u001b[39m.\u001b[39;49mget_child() \u001b[39mif\u001b[39;49;00m run_manager \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    787\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtool_run_kwargs,\n\u001b[1;32m    788\u001b[0m     )\n\u001b[1;32m    789\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    790\u001b[0m     tool_run_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39magent\u001b[39m.\u001b[39mtool_run_logging_kwargs()\n",
      "File \u001b[0;32m~/anaconda3/envs/llm/lib/python3.10/site-packages/langchain/tools/base.py:253\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mException\u001b[39;00m, \u001b[39mKeyboardInterrupt\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    252\u001b[0m     run_manager\u001b[39m.\u001b[39mon_tool_error(e)\n\u001b[0;32m--> 253\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    254\u001b[0m run_manager\u001b[39m.\u001b[39mon_tool_end(\u001b[39mstr\u001b[39m(observation), color\u001b[39m=\u001b[39mcolor, name\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    255\u001b[0m \u001b[39mreturn\u001b[39;00m observation\n",
      "File \u001b[0;32m~/anaconda3/envs/llm/lib/python3.10/site-packages/langchain/tools/base.py:247\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    245\u001b[0m     tool_args, tool_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_to_args_and_kwargs(tool_input)\n\u001b[1;32m    246\u001b[0m     observation \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 247\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(\u001b[39m*\u001b[39;49mtool_args, run_manager\u001b[39m=\u001b[39;49mrun_manager, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtool_kwargs)\n\u001b[1;32m    248\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    249\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run(\u001b[39m*\u001b[39mtool_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtool_kwargs)\n\u001b[1;32m    250\u001b[0m     )\n\u001b[1;32m    251\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mException\u001b[39;00m, \u001b[39mKeyboardInterrupt\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    252\u001b[0m     run_manager\u001b[39m.\u001b[39mon_tool_error(e)\n",
      "File \u001b[0;32m~/anaconda3/envs/llm/lib/python3.10/site-packages/langchain/tools/base.py:349\u001b[0m, in \u001b[0;36mTool._run\u001b[0;34m(self, run_manager, *args, **kwargs)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Use the tool.\"\"\"\u001b[39;00m\n\u001b[1;32m    347\u001b[0m new_argument_supported \u001b[39m=\u001b[39m signature(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc)\u001b[39m.\u001b[39mparameters\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mcallbacks\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    348\u001b[0m \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 349\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc(\n\u001b[1;32m    350\u001b[0m         \u001b[39m*\u001b[39;49margs,\n\u001b[1;32m    351\u001b[0m         callbacks\u001b[39m=\u001b[39;49mrun_manager\u001b[39m.\u001b[39;49mget_child() \u001b[39mif\u001b[39;49;00m run_manager \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    352\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    353\u001b[0m     )\n\u001b[1;32m    354\u001b[0m     \u001b[39mif\u001b[39;00m new_argument_supported\n\u001b[1;32m    355\u001b[0m     \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    356\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/llm/lib/python3.10/site-packages/langchain/chains/base.py:238\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, callbacks, *args, **kwargs)\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    237\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`run` supports only one positional argument.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 238\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(args[\u001b[39m0\u001b[39;49m], callbacks\u001b[39m=\u001b[39;49mcallbacks)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys[\u001b[39m0\u001b[39m]]\n\u001b[1;32m    240\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[1;32m    241\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(kwargs, callbacks\u001b[39m=\u001b[39mcallbacks)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys[\u001b[39m0\u001b[39m]]\n",
      "File \u001b[0;32m~/anaconda3/envs/llm/lib/python3.10/site-packages/langchain/chains/base.py:142\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    141\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 142\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    143\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    144\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(inputs, outputs, return_only_outputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/llm/lib/python3.10/site-packages/langchain/chains/base.py:136\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks)\u001b[0m\n\u001b[1;32m    130\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[1;32m    131\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m},\n\u001b[1;32m    132\u001b[0m     inputs,\n\u001b[1;32m    133\u001b[0m )\n\u001b[1;32m    134\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    135\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 136\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m    137\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    138\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[1;32m    139\u001b[0m     )\n\u001b[1;32m    140\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    141\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/anaconda3/envs/llm/lib/python3.10/site-packages/langchain/chains/llm_math/base.py:146\u001b[0m, in \u001b[0;36mLLMMathChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    140\u001b[0m _run_manager\u001b[39m.\u001b[39mon_text(inputs[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_key])\n\u001b[1;32m    141\u001b[0m llm_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mllm_chain\u001b[39m.\u001b[39mpredict(\n\u001b[1;32m    142\u001b[0m     question\u001b[39m=\u001b[39minputs[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_key],\n\u001b[1;32m    143\u001b[0m     stop\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39m```output\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m    144\u001b[0m     callbacks\u001b[39m=\u001b[39m_run_manager\u001b[39m.\u001b[39mget_child(),\n\u001b[1;32m    145\u001b[0m )\n\u001b[0;32m--> 146\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_llm_result(llm_output, _run_manager)\n",
      "File \u001b[0;32m~/anaconda3/envs/llm/lib/python3.10/site-packages/langchain/chains/llm_math/base.py:100\u001b[0m, in \u001b[0;36mLLMMathChain._process_llm_result\u001b[0;34m(self, llm_output, run_manager)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[39mif\u001b[39;00m text_match:\n\u001b[1;32m     99\u001b[0m     expression \u001b[39m=\u001b[39m text_match\u001b[39m.\u001b[39mgroup(\u001b[39m1\u001b[39m)\n\u001b[0;32m--> 100\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_evaluate_expression(expression)\n\u001b[1;32m    101\u001b[0m     run_manager\u001b[39m.\u001b[39mon_text(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mAnswer: \u001b[39m\u001b[39m\"\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[1;32m    102\u001b[0m     run_manager\u001b[39m.\u001b[39mon_text(output, color\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39myellow\u001b[39m\u001b[39m\"\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n",
      "File \u001b[0;32m~/anaconda3/envs/llm/lib/python3.10/site-packages/langchain/chains/llm_math/base.py:87\u001b[0m, in \u001b[0;36mLLMMathChain._evaluate_expression\u001b[0;34m(self, expression)\u001b[0m\n\u001b[1;32m     79\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\n\u001b[1;32m     80\u001b[0m         numexpr\u001b[39m.\u001b[39mevaluate(\n\u001b[1;32m     81\u001b[0m             expression\u001b[39m.\u001b[39mstrip(),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     84\u001b[0m         )\n\u001b[1;32m     85\u001b[0m     )\n\u001b[1;32m     86\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m---> 87\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m. Please try again with a valid numerical expression\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     89\u001b[0m \u001b[39m# Remove any leading and trailing brackets from the output\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[39mreturn\u001b[39;00m re\u001b[39m.\u001b[39msub(\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m^\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m[|\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m]$\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m, output)\n",
      "\u001b[0;31mValueError\u001b[0m: 'VariableNode' object has no attribute 'sort'. Please try again with a valid numerical expression"
     ]
    }
   ],
   "source": [
    "# First, let's load the language model we're going to use to control the agent.\n",
    "llm = OpenAI(temperature=0.0)\n",
    "\n",
    "# Next, let's load some tools to use. \n",
    "# Note that the `llm-math` tool uses an LLM, so we need to pass that in.\n",
    "tools = load_tools([\"llm-math\"], llm=llm)\n",
    "\n",
    "# Finally, let's initialize an agent with the tools, the language model, \n",
    "# and the type of agent we want to use.\n",
    "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)\n",
    "\n",
    "# Now let's test it out!\n",
    "\n",
    "query = input(\"Human: \")\n",
    "text = f\"Human: {query}\"\n",
    "agent.run(query)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1af836b3",
   "metadata": {},
   "source": [
    "### Demo 6: Evaluation\n",
    "\n",
    "Evaluation of chains is difficult to perform because of: 1) Lack of data and 2) Lack of metrics.\n",
    "\n",
    "- Lack of data\n",
    "\n",
    "Unlike machine learning problems, there is not enough data to evaluate chains. As such, the evaluation is performed on specific examples only. For example, Q&A on documents with known answers. LangChain provides a small number of datasets for evaluation.\n",
    "\n",
    "- Lack of metrics\n",
    "\n",
    "Unlike machine learning problems where there are more or less precise answers (e.g. accuracy on classification, mAP on detection, etc.), there are no precise answers in language. As such, the evaluation is more complicated. How do you evaluate the quality of a conversation or essay?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4120c014",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mevaluation\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mloading\u001b[39;00m \u001b[39mimport\u001b[39;00m load_dataset\n\u001b[1;32m      5\u001b[0m os\u001b[39m.\u001b[39menviron[\u001b[39m\"\u001b[39m\u001b[39mLANGCHAIN_HANDLER\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mlangchain\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m dataset \u001b[39m=\u001b[39m load_dataset(\u001b[39m\"\u001b[39;49m\u001b[39mquestion-answering-state-of-the-union\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/llm/lib/python3.10/site-packages/langchain/evaluation/loading.py:5\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(uri)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_dataset\u001b[39m(uri: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[Dict]:\n\u001b[0;32m----> 5\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m load_dataset\n\u001b[1;32m      7\u001b[0m     dataset \u001b[39m=\u001b[39m load_dataset(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLangChainDatasets/\u001b[39m\u001b[39m{\u001b[39;00muri\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m     \u001b[39mreturn\u001b[39;00m [d \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m dataset[\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m]]\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'datasets'"
     ]
    }
   ],
   "source": [
    "# Comment this out if you are NOT using tracing\n",
    "import os\n",
    "\n",
    "from langchain.evaluation.loading import load_dataset\n",
    "\n",
    "os.environ[\"LANGCHAIN_HANDLER\"] = \"langchain\"\n",
    "dataset = load_dataset(\"question-answering-state-of-the-union\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "82ad6d7bc5c4d1338129f53582d686f501ccbc16afd0f50ed25b05b303292daa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
