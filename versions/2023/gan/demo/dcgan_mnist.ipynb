{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        kernel_size = 5\n",
    "        self.blocks = nn.ModuleList()\n",
    "        self.fc = nn.Linear(latent_dim, 7 * 7 * 128)\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(128, 128, kernel_size, stride=2, padding=2, output_padding=1),\n",
    "        )\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size, stride=2, padding=2, output_padding=1),\n",
    "        )\n",
    "        self.block3 = nn.Sequential(\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size, stride=1, padding=2),\n",
    "        )\n",
    "        self.block4 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32, 1, kernel_size, stride=1, padding=2),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, z):\n",
    "        x = self.fc(z)\n",
    "        x = x.view(-1, 128, 7, 7)\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        img = self.block4(x)\n",
    "        return img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        kernel_size = 5\n",
    "        layer_filters = [32, 64, 128, 256]\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(1, layer_filters[0], kernel_size, stride=2, padding=2),\n",
    "        )\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(layer_filters[0], layer_filters[1], kernel_size, stride=2, padding=2),\n",
    "        )\n",
    "        self.block3 = nn.Sequential(\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(layer_filters[1], layer_filters[2], kernel_size, stride=2, padding=2),\n",
    "        )\n",
    "        self.block4 = nn.Sequential(\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(layer_filters[2], layer_filters[3], kernel_size, stride=1, padding=2),     \n",
    "        )\n",
    "        self.fc = nn.Linear(4 * 4 * layer_filters[3], 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adversarial(nn.Module):\n",
    "    def __init__(self, generator, discriminator):\n",
    "        super(Adversarial, self).__init__()\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "\n",
    "    def forward(self, z):\n",
    "        img = self.generator(z)\n",
    "        validity = self.discriminator(img)\n",
    "        return validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "# Define the transformation to apply to the MNIST dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Load the MNIST dataset\n",
    "train_dataset = torchvision.datasets.MNIST(root='~/data', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='~/data', train=False, transform=transform, download=True)\n",
    "\n",
    "# Create dataloaders for training and testing\n",
    "batch_size = 64\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "def save_generated_images(generator, device, epoch=1):\n",
    "    # Generate random noise vectors\n",
    "    noise = torch.randn(16, 100).to(device)\n",
    "    \n",
    "    # Generate images using the generator\n",
    "    with torch.no_grad():\n",
    "        generated_images = generator(noise).detach().cpu()\n",
    "    \n",
    "    # Create a grid of 4 x 4 images\n",
    "    grid = vutils.make_grid(generated_images, nrow=4, padding=2, normalize=True)\n",
    "    \n",
    "    # Save the grid of images\n",
    "    filename = 'gen_img_ep-%s.png' % (epoch)\n",
    "    vutils.save_image(grid, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(generator, discriminator, \n",
    "          adversarial, trainloader,\n",
    "          epochs=50):\n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "    criterion = nn.BCELoss()\n",
    "    lr = 2e-4\n",
    "    decay = 6e-8\n",
    "    factor = 0.5\n",
    "    optimizer_g = torch.optim.RMSprop(generator.parameters(), \n",
    "                                    lr=lr*factor, weight_decay=decay*factor)    \n",
    "    optimizer_d = torch.optim.RMSprop(discriminator.parameters(),\n",
    "                                    lr=lr, weight_decay=decay) \n",
    "    #scheduler_g = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_g, T_max=epochs)\n",
    "    #scheduler_d = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_d, T_max=epochs)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i, (real_imgs, _) in enumerate(trainloader):\n",
    "            real_imgs = real_imgs.to(device)\n",
    "            batch_size = real_imgs.shape[0]\n",
    "            real_labels = torch.ones(batch_size, 1, requires_grad=False).to(device)\n",
    "            fake_labels = torch.zeros(batch_size, 1, requires_grad=False).to(device)\n",
    "            z = torch.randn(batch_size, 100).to(device)\n",
    "            \n",
    "            # Train discriminator\n",
    "            optimizer_d.zero_grad()\n",
    "            generator.eval()\n",
    "            with torch.no_grad():\n",
    "                fake_imgs = generator(z)\n",
    "        \n",
    "            real_out = discriminator(real_imgs)\n",
    "            fake_out = discriminator(fake_imgs)\n",
    "            loss_real = criterion(real_out, real_labels)\n",
    "            loss_fake = criterion(fake_out, fake_labels)\n",
    "            loss_d = loss_real + loss_fake\n",
    "            loss_d.backward()\n",
    "            optimizer_d.step()\n",
    "            \n",
    "            # Train generator\n",
    "            optimizer_g.zero_grad()\n",
    "            generator.train()\n",
    "            z = torch.randn(batch_size, 100, requires_grad=False).to(device)\n",
    "            \n",
    "            fake_out = adversarial(z)\n",
    "            loss_g = criterion(fake_out, real_labels)\n",
    "            loss_g.backward()\n",
    "            optimizer_g.step()\n",
    "            if i % 100 == 0:\n",
    "                print('Epoch: %d, Iter: %d, Loss D: %.6f, Loss G: %.6f' % (epoch, i, loss_d.item(), loss_g.item()))\n",
    "        #scheduler_g.step()\n",
    "        #scheduler_d.step()\n",
    "        print('Learning Rate (Generator):', optimizer_g.param_groups[0]['lr'])\n",
    "        print('Learning Rate (Discriminator):', optimizer_d.param_groups[0]['lr'])\n",
    "        save_generated_images(generator, device, epoch=epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Iter: 0, Loss D: 1.385114, Loss G: 1.113374\n",
      "Epoch: 0, Iter: 100, Loss D: 0.000456, Loss G: 7.802855\n",
      "Epoch: 0, Iter: 200, Loss D: 0.207746, Loss G: 3.632315\n",
      "Epoch: 0, Iter: 300, Loss D: 0.001795, Loss G: 6.726063\n",
      "Epoch: 0, Iter: 400, Loss D: 0.001615, Loss G: 7.410963\n",
      "Epoch: 0, Iter: 500, Loss D: 0.001772, Loss G: 7.345804\n",
      "Epoch: 0, Iter: 600, Loss D: 0.000196, Loss G: 8.635316\n",
      "Epoch: 0, Iter: 700, Loss D: 0.002317, Loss G: 6.019722\n",
      "Epoch: 0, Iter: 800, Loss D: 0.000571, Loss G: 7.443192\n",
      "Epoch: 0, Iter: 900, Loss D: 0.000211, Loss G: 8.648391\n",
      "Learning Rate (Generator): 0.0001\n",
      "Learning Rate (Discriminator): 0.0002\n",
      "Epoch: 1, Iter: 0, Loss D: 0.000287, Loss G: 8.349941\n",
      "Epoch: 1, Iter: 100, Loss D: 0.000052, Loss G: 9.929526\n",
      "Epoch: 1, Iter: 200, Loss D: 0.000025, Loss G: 10.655956\n",
      "Epoch: 1, Iter: 300, Loss D: 0.000023, Loss G: 10.723509\n",
      "Epoch: 1, Iter: 400, Loss D: 0.064607, Loss G: 3.696424\n",
      "Epoch: 1, Iter: 500, Loss D: 0.004399, Loss G: 5.603803\n",
      "Epoch: 1, Iter: 600, Loss D: 1.133105, Loss G: 1.359200\n",
      "Epoch: 1, Iter: 700, Loss D: 0.916935, Loss G: 2.299670\n",
      "Epoch: 1, Iter: 800, Loss D: 0.314082, Loss G: 2.577312\n",
      "Epoch: 1, Iter: 900, Loss D: 1.035908, Loss G: 1.245109\n",
      "Learning Rate (Generator): 0.0001\n",
      "Learning Rate (Discriminator): 0.0002\n",
      "Epoch: 2, Iter: 0, Loss D: 1.349583, Loss G: 2.290414\n",
      "Epoch: 2, Iter: 100, Loss D: 1.233257, Loss G: 2.846426\n",
      "Epoch: 2, Iter: 200, Loss D: 0.958458, Loss G: 1.070952\n",
      "Epoch: 2, Iter: 300, Loss D: 0.982046, Loss G: 1.532557\n",
      "Epoch: 2, Iter: 400, Loss D: 0.940159, Loss G: 1.007911\n",
      "Epoch: 2, Iter: 500, Loss D: 1.013382, Loss G: 1.149679\n",
      "Epoch: 2, Iter: 600, Loss D: 0.811480, Loss G: 1.163583\n",
      "Epoch: 2, Iter: 700, Loss D: 0.949928, Loss G: 2.467901\n",
      "Epoch: 2, Iter: 800, Loss D: 0.772713, Loss G: 1.711895\n",
      "Epoch: 2, Iter: 900, Loss D: 0.947252, Loss G: 1.130172\n",
      "Learning Rate (Generator): 0.0001\n",
      "Learning Rate (Discriminator): 0.0002\n",
      "Epoch: 3, Iter: 0, Loss D: 0.820691, Loss G: 1.616774\n",
      "Epoch: 3, Iter: 100, Loss D: 0.789215, Loss G: 1.452754\n",
      "Epoch: 3, Iter: 200, Loss D: 0.903972, Loss G: 1.177573\n",
      "Epoch: 3, Iter: 300, Loss D: 0.968041, Loss G: 1.304723\n",
      "Epoch: 3, Iter: 400, Loss D: 1.161275, Loss G: 1.112315\n",
      "Epoch: 3, Iter: 500, Loss D: 1.170537, Loss G: 0.887355\n",
      "Epoch: 3, Iter: 600, Loss D: 0.813863, Loss G: 1.965890\n",
      "Epoch: 3, Iter: 700, Loss D: 0.839613, Loss G: 1.313763\n",
      "Epoch: 3, Iter: 800, Loss D: 0.644904, Loss G: 2.012379\n",
      "Epoch: 3, Iter: 900, Loss D: 0.989619, Loss G: 2.307695\n",
      "Learning Rate (Generator): 0.0001\n",
      "Learning Rate (Discriminator): 0.0002\n",
      "Epoch: 4, Iter: 0, Loss D: 1.002332, Loss G: 1.176123\n",
      "Epoch: 4, Iter: 100, Loss D: 0.852136, Loss G: 1.511677\n",
      "Epoch: 4, Iter: 200, Loss D: 0.818198, Loss G: 2.375922\n",
      "Epoch: 4, Iter: 300, Loss D: 0.794986, Loss G: 1.042360\n",
      "Epoch: 4, Iter: 400, Loss D: 0.880271, Loss G: 2.111309\n",
      "Epoch: 4, Iter: 500, Loss D: 0.821061, Loss G: 1.905221\n",
      "Epoch: 4, Iter: 600, Loss D: 0.983216, Loss G: 0.984639\n",
      "Epoch: 4, Iter: 700, Loss D: 0.756864, Loss G: 1.590273\n",
      "Epoch: 4, Iter: 800, Loss D: 0.677783, Loss G: 2.090955\n",
      "Epoch: 4, Iter: 900, Loss D: 0.923550, Loss G: 2.157531\n",
      "Learning Rate (Generator): 0.0001\n",
      "Learning Rate (Discriminator): 0.0002\n",
      "Epoch: 5, Iter: 0, Loss D: 1.061747, Loss G: 1.249801\n",
      "Epoch: 5, Iter: 100, Loss D: 0.855764, Loss G: 1.769608\n",
      "Epoch: 5, Iter: 200, Loss D: 0.715524, Loss G: 1.720704\n",
      "Epoch: 5, Iter: 300, Loss D: 0.956406, Loss G: 2.592918\n",
      "Epoch: 5, Iter: 400, Loss D: 0.638264, Loss G: 2.275707\n",
      "Epoch: 5, Iter: 500, Loss D: 0.846833, Loss G: 2.316789\n",
      "Epoch: 5, Iter: 600, Loss D: 0.860755, Loss G: 1.719702\n",
      "Epoch: 5, Iter: 700, Loss D: 0.821128, Loss G: 1.228930\n",
      "Epoch: 5, Iter: 800, Loss D: 0.842297, Loss G: 1.363942\n",
      "Epoch: 5, Iter: 900, Loss D: 0.907970, Loss G: 1.096201\n",
      "Learning Rate (Generator): 0.0001\n",
      "Learning Rate (Discriminator): 0.0002\n",
      "Epoch: 6, Iter: 0, Loss D: 0.868653, Loss G: 1.771752\n",
      "Epoch: 6, Iter: 100, Loss D: 0.968613, Loss G: 2.136151\n",
      "Epoch: 6, Iter: 200, Loss D: 0.732807, Loss G: 1.977192\n",
      "Epoch: 6, Iter: 300, Loss D: 0.784635, Loss G: 2.211308\n",
      "Epoch: 6, Iter: 400, Loss D: 0.922160, Loss G: 2.680581\n",
      "Epoch: 6, Iter: 500, Loss D: 0.730698, Loss G: 2.416232\n",
      "Epoch: 6, Iter: 600, Loss D: 1.319306, Loss G: 1.160603\n",
      "Epoch: 6, Iter: 700, Loss D: 0.798921, Loss G: 1.693381\n",
      "Epoch: 6, Iter: 800, Loss D: 1.245721, Loss G: 2.641220\n",
      "Epoch: 6, Iter: 900, Loss D: 0.759699, Loss G: 1.653334\n",
      "Learning Rate (Generator): 0.0001\n",
      "Learning Rate (Discriminator): 0.0002\n",
      "Epoch: 7, Iter: 0, Loss D: 0.784589, Loss G: 1.612214\n",
      "Epoch: 7, Iter: 100, Loss D: 0.843705, Loss G: 2.299712\n",
      "Epoch: 7, Iter: 200, Loss D: 0.958886, Loss G: 1.319159\n",
      "Epoch: 7, Iter: 300, Loss D: 0.792160, Loss G: 1.621084\n",
      "Epoch: 7, Iter: 400, Loss D: 0.893388, Loss G: 1.735283\n",
      "Epoch: 7, Iter: 500, Loss D: 0.887543, Loss G: 2.880747\n",
      "Epoch: 7, Iter: 600, Loss D: 0.837630, Loss G: 1.623178\n",
      "Epoch: 7, Iter: 700, Loss D: 0.775612, Loss G: 1.691641\n",
      "Epoch: 7, Iter: 800, Loss D: 0.801344, Loss G: 1.477576\n",
      "Epoch: 7, Iter: 900, Loss D: 0.672744, Loss G: 2.323522\n",
      "Learning Rate (Generator): 0.0001\n",
      "Learning Rate (Discriminator): 0.0002\n",
      "Epoch: 8, Iter: 0, Loss D: 0.877821, Loss G: 1.574652\n",
      "Epoch: 8, Iter: 100, Loss D: 0.662596, Loss G: 1.888583\n",
      "Epoch: 8, Iter: 200, Loss D: 0.867751, Loss G: 1.449064\n",
      "Epoch: 8, Iter: 300, Loss D: 0.831555, Loss G: 1.354119\n",
      "Epoch: 8, Iter: 400, Loss D: 0.666983, Loss G: 1.968796\n",
      "Epoch: 8, Iter: 500, Loss D: 0.797998, Loss G: 1.367212\n",
      "Epoch: 8, Iter: 600, Loss D: 0.780343, Loss G: 2.494822\n",
      "Epoch: 8, Iter: 700, Loss D: 0.815334, Loss G: 2.472234\n",
      "Epoch: 8, Iter: 800, Loss D: 0.888812, Loss G: 2.141673\n",
      "Epoch: 8, Iter: 900, Loss D: 0.804724, Loss G: 1.795959\n",
      "Learning Rate (Generator): 0.0001\n",
      "Learning Rate (Discriminator): 0.0002\n",
      "Epoch: 9, Iter: 0, Loss D: 0.947739, Loss G: 2.157556\n",
      "Epoch: 9, Iter: 100, Loss D: 0.936165, Loss G: 2.472663\n",
      "Epoch: 9, Iter: 200, Loss D: 0.962346, Loss G: 1.569280\n",
      "Epoch: 9, Iter: 300, Loss D: 0.709284, Loss G: 2.068113\n",
      "Epoch: 9, Iter: 400, Loss D: 0.822871, Loss G: 2.678484\n",
      "Epoch: 9, Iter: 500, Loss D: 0.687372, Loss G: 2.011474\n",
      "Epoch: 9, Iter: 600, Loss D: 0.966108, Loss G: 1.553684\n",
      "Epoch: 9, Iter: 700, Loss D: 0.756058, Loss G: 1.886290\n",
      "Epoch: 9, Iter: 800, Loss D: 0.996540, Loss G: 1.378457\n",
      "Epoch: 9, Iter: 900, Loss D: 0.932331, Loss G: 1.286076\n",
      "Learning Rate (Generator): 0.0001\n",
      "Learning Rate (Discriminator): 0.0002\n",
      "Epoch: 10, Iter: 0, Loss D: 0.840182, Loss G: 1.549715\n",
      "Epoch: 10, Iter: 100, Loss D: 0.804343, Loss G: 2.158410\n",
      "Epoch: 10, Iter: 200, Loss D: 0.796729, Loss G: 1.880436\n",
      "Epoch: 10, Iter: 300, Loss D: 0.715133, Loss G: 1.224901\n",
      "Epoch: 10, Iter: 400, Loss D: 1.079095, Loss G: 2.206991\n",
      "Epoch: 10, Iter: 500, Loss D: 0.825220, Loss G: 1.559181\n",
      "Epoch: 10, Iter: 600, Loss D: 0.844652, Loss G: 1.836775\n",
      "Epoch: 10, Iter: 700, Loss D: 0.833643, Loss G: 1.999450\n",
      "Epoch: 10, Iter: 800, Loss D: 0.898059, Loss G: 1.368709\n",
      "Epoch: 10, Iter: 900, Loss D: 0.800196, Loss G: 1.393115\n",
      "Learning Rate (Generator): 0.0001\n",
      "Learning Rate (Discriminator): 0.0002\n",
      "Epoch: 11, Iter: 0, Loss D: 1.059500, Loss G: 2.382520\n",
      "Epoch: 11, Iter: 100, Loss D: 0.635830, Loss G: 2.007530\n",
      "Epoch: 11, Iter: 200, Loss D: 0.897052, Loss G: 1.572150\n",
      "Epoch: 11, Iter: 300, Loss D: 0.862189, Loss G: 1.861421\n",
      "Epoch: 11, Iter: 400, Loss D: 0.751130, Loss G: 1.909060\n",
      "Epoch: 11, Iter: 500, Loss D: 0.891888, Loss G: 2.051413\n",
      "Epoch: 11, Iter: 600, Loss D: 0.736865, Loss G: 1.580859\n",
      "Epoch: 11, Iter: 700, Loss D: 1.129451, Loss G: 1.711672\n",
      "Epoch: 11, Iter: 800, Loss D: 0.821442, Loss G: 1.354622\n",
      "Epoch: 11, Iter: 900, Loss D: 0.767176, Loss G: 2.058189\n",
      "Learning Rate (Generator): 0.0001\n",
      "Learning Rate (Discriminator): 0.0002\n",
      "Epoch: 12, Iter: 0, Loss D: 0.797763, Loss G: 2.235462\n",
      "Epoch: 12, Iter: 100, Loss D: 0.730848, Loss G: 1.708583\n",
      "Epoch: 12, Iter: 200, Loss D: 0.679427, Loss G: 1.750892\n",
      "Epoch: 12, Iter: 300, Loss D: 1.180834, Loss G: 1.828503\n",
      "Epoch: 12, Iter: 400, Loss D: 0.911529, Loss G: 2.191184\n",
      "Epoch: 12, Iter: 500, Loss D: 0.813177, Loss G: 1.842855\n",
      "Epoch: 12, Iter: 600, Loss D: 0.802391, Loss G: 1.537954\n",
      "Epoch: 12, Iter: 700, Loss D: 0.966758, Loss G: 1.949273\n",
      "Epoch: 12, Iter: 800, Loss D: 0.820642, Loss G: 1.702002\n",
      "Epoch: 12, Iter: 900, Loss D: 0.799670, Loss G: 2.061219\n",
      "Learning Rate (Generator): 0.0001\n",
      "Learning Rate (Discriminator): 0.0002\n",
      "Epoch: 13, Iter: 0, Loss D: 0.728397, Loss G: 1.996287\n",
      "Epoch: 13, Iter: 100, Loss D: 0.874034, Loss G: 1.248564\n",
      "Epoch: 13, Iter: 200, Loss D: 0.738520, Loss G: 1.743296\n",
      "Epoch: 13, Iter: 300, Loss D: 0.849308, Loss G: 1.669341\n",
      "Epoch: 13, Iter: 400, Loss D: 0.706980, Loss G: 1.851329\n",
      "Epoch: 13, Iter: 500, Loss D: 0.909085, Loss G: 1.201982\n",
      "Epoch: 13, Iter: 600, Loss D: 0.739131, Loss G: 1.409613\n",
      "Epoch: 13, Iter: 700, Loss D: 0.694980, Loss G: 1.843546\n",
      "Epoch: 13, Iter: 800, Loss D: 0.832752, Loss G: 1.760352\n",
      "Epoch: 13, Iter: 900, Loss D: 1.031309, Loss G: 1.359000\n",
      "Learning Rate (Generator): 0.0001\n",
      "Learning Rate (Discriminator): 0.0002\n",
      "Epoch: 14, Iter: 0, Loss D: 0.961179, Loss G: 1.626496\n",
      "Epoch: 14, Iter: 100, Loss D: 1.000242, Loss G: 2.344560\n",
      "Epoch: 14, Iter: 200, Loss D: 0.847749, Loss G: 1.928832\n",
      "Epoch: 14, Iter: 300, Loss D: 0.931241, Loss G: 1.278445\n",
      "Epoch: 14, Iter: 400, Loss D: 0.761638, Loss G: 2.173168\n",
      "Epoch: 14, Iter: 500, Loss D: 0.745522, Loss G: 2.146063\n",
      "Epoch: 14, Iter: 600, Loss D: 0.908388, Loss G: 2.244428\n",
      "Epoch: 14, Iter: 700, Loss D: 0.947508, Loss G: 1.559827\n",
      "Epoch: 14, Iter: 800, Loss D: 0.830462, Loss G: 1.140868\n",
      "Epoch: 14, Iter: 900, Loss D: 0.866143, Loss G: 1.384605\n",
      "Learning Rate (Generator): 0.0001\n",
      "Learning Rate (Discriminator): 0.0002\n",
      "Epoch: 15, Iter: 0, Loss D: 0.913141, Loss G: 2.562263\n",
      "Epoch: 15, Iter: 100, Loss D: 0.732162, Loss G: 1.610431\n",
      "Epoch: 15, Iter: 200, Loss D: 0.867833, Loss G: 1.372217\n",
      "Epoch: 15, Iter: 300, Loss D: 0.830107, Loss G: 1.650641\n",
      "Epoch: 15, Iter: 400, Loss D: 1.038765, Loss G: 1.239965\n",
      "Epoch: 15, Iter: 500, Loss D: 0.814566, Loss G: 1.692459\n",
      "Epoch: 15, Iter: 600, Loss D: 0.870351, Loss G: 2.253854\n",
      "Epoch: 15, Iter: 700, Loss D: 0.847791, Loss G: 1.487889\n",
      "Epoch: 15, Iter: 800, Loss D: 0.925020, Loss G: 1.108681\n",
      "Epoch: 15, Iter: 900, Loss D: 0.705898, Loss G: 2.268556\n",
      "Learning Rate (Generator): 0.0001\n",
      "Learning Rate (Discriminator): 0.0002\n",
      "Epoch: 16, Iter: 0, Loss D: 0.768451, Loss G: 1.322673\n",
      "Epoch: 16, Iter: 100, Loss D: 0.902564, Loss G: 1.439967\n",
      "Epoch: 16, Iter: 200, Loss D: 0.887128, Loss G: 1.657815\n",
      "Epoch: 16, Iter: 300, Loss D: 0.991012, Loss G: 1.916840\n",
      "Epoch: 16, Iter: 400, Loss D: 0.935760, Loss G: 2.304062\n",
      "Epoch: 16, Iter: 500, Loss D: 0.717913, Loss G: 1.619040\n",
      "Epoch: 16, Iter: 600, Loss D: 0.699730, Loss G: 1.782883\n",
      "Epoch: 16, Iter: 700, Loss D: 0.686344, Loss G: 2.168547\n",
      "Epoch: 16, Iter: 800, Loss D: 0.830237, Loss G: 1.796629\n",
      "Epoch: 16, Iter: 900, Loss D: 0.776991, Loss G: 1.472927\n",
      "Learning Rate (Generator): 0.0001\n",
      "Learning Rate (Discriminator): 0.0002\n",
      "Epoch: 17, Iter: 0, Loss D: 0.941635, Loss G: 2.112975\n",
      "Epoch: 17, Iter: 100, Loss D: 0.831189, Loss G: 2.207576\n",
      "Epoch: 17, Iter: 200, Loss D: 0.856868, Loss G: 1.930930\n",
      "Epoch: 17, Iter: 300, Loss D: 0.815891, Loss G: 2.196516\n",
      "Epoch: 17, Iter: 400, Loss D: 0.782441, Loss G: 1.912092\n"
     ]
    }
   ],
   "source": [
    "generator = Generator(100).to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "adversarial = Adversarial(generator, discriminator).to(device)\n",
    "\n",
    "train(generator, discriminator, adversarial, train_dataloader)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
