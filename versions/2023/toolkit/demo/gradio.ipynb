{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "521a8e94",
   "metadata": {},
   "source": [
    "### Gradio and HuggingFace\n",
    "\n",
    "In this demo, we show how to build ready to deploy or use deep learning models. \n",
    "\n",
    "Hugging Face hosts thousands of pre-trained models in [Model Hub](https://huggingface.co/models). They also built high-level APIs so we can easily use and deploy pre-trained models using [Pipeline](https://huggingface.co/docs/transformers/main_classes/pipelines). \n",
    "\n",
    "`gradio` provides APIs so we can easily build web applications that use our pre-trained models from Hugging Face. `gradio` also provides APIs so we can easily incorporate input and output web UIs.\n",
    "\n",
    "After building the `gradio`, we can have permanent hosting using [Hugging Face Spaces](https://huggingface.co/blog/gradio-spaces). \n",
    "\n",
    "Let us first install Hugging Face `transformers` and `gradio`.\n",
    "\n",
    "**Note:** For some examples, it is best to launch the app in another tab to enable access to the required inputs such as microphone or webcam. Running the app may also lock the `python` kernel and the notebook becomes unresponsive. In that case, please restart the kernel and clear the output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54da9029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (4.34.1)\n",
      "Requirement already satisfied: filelock in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from transformers) (3.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from transformers) (0.17.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: requests in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from requests->transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from requests->transformers) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from requests->transformers) (2023.5.7)\n",
      "Requirement already satisfied: gradio in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (3.50.2)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from gradio) (23.2.1)\n",
      "Requirement already satisfied: altair<6.0,>=4.2.0 in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from gradio) (5.1.2)\n",
      "Requirement already satisfied: fastapi in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from gradio) (0.100.0)\n",
      "Requirement already satisfied: ffmpy in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from gradio) (0.3.1)\n",
      "Requirement already satisfied: gradio-client==0.6.1 in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from gradio) (0.6.1)\n",
      "Requirement already satisfied: httpx in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from gradio) (0.25.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.14.0 in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from gradio) (0.17.3)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from gradio) (6.1.0)\n",
      "Requirement already satisfied: jinja2<4.0 in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from gradio) (3.1.2)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from gradio) (2.1.3)\n",
      "Requirement already satisfied: matplotlib~=3.0 in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from gradio) (3.7.2)\n",
      "Requirement already satisfied: numpy~=1.0 in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from gradio) (1.23.5)\n",
      "Requirement already satisfied: orjson~=3.0 in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from gradio) (3.9.9)\n",
      "Requirement already satisfied: packaging in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from gradio) (23.1)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from gradio) (2.1.1)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from gradio) (10.0.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from gradio) (1.10.11)\n",
      "Requirement already satisfied: pydub in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from gradio) (0.0.6)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from gradio) (6.0.1)\n",
      "Requirement already satisfied: requests~=2.0 in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from gradio) (2.31.0)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from gradio) (4.7.1)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from gradio) (0.23.1)\n",
      "Requirement already satisfied: websockets<12.0,>=10.0 in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from gradio) (11.0.3)\n",
      "Requirement already satisfied: fsspec in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from gradio-client==0.6.1->gradio) (2023.6.0)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio) (4.19.1)\n",
      "Requirement already satisfied: toolz in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio) (0.12.0)\n",
      "Requirement already satisfied: filelock in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from huggingface-hub>=0.14.0->gradio) (3.12.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from huggingface-hub>=0.14.0->gradio) (4.65.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (4.41.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (1.4.4)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from requests~=2.0->gradio) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from requests~=2.0->gradio) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from requests~=2.0->gradio) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from requests~=2.0->gradio) (2023.5.7)\n",
      "Requirement already satisfied: click>=7.0 in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from uvicorn>=0.14.0->gradio) (8.1.6)\n",
      "Requirement already satisfied: h11>=0.8 in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from uvicorn>=0.14.0->gradio) (0.14.0)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from fastapi->gradio) (0.27.0)\n",
      "Requirement already satisfied: httpcore<0.19.0,>=0.18.0 in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from httpx->gradio) (0.18.0)\n",
      "Requirement already satisfied: sniffio in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from httpx->gradio) (1.3.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from httpcore<0.19.0,>=0.18.0->httpx->gradio) (3.7.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.10.6)\n",
      "Requirement already satisfied: six>=1.5 in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: exceptiongroup in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from anyio<5.0,>=3.0->httpcore<0.19.0,>=0.18.0->httpx->gradio) (1.1.2)\n",
      "Requirement already satisfied: torch in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (2.0.0)\n",
      "Collecting torch\n",
      "  Downloading torch-2.1.0-cp310-none-macosx_10_9_x86_64.whl (147.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.0/147.0 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torchvision in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (0.15.1)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.16.0-cp310-cp310-macosx_10_13_x86_64.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: filelock in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from torch) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: sympy in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from torch) (2023.6.0)\n",
      "Requirement already satisfied: numpy in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from torchvision) (1.23.5)\n",
      "Requirement already satisfied: requests in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from torchvision) (10.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from requests->torchvision) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from requests->torchvision) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from requests->torchvision) (2023.5.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Installing collected packages: torch, torchvision\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.0.0\n",
      "    Uninstalling torch-2.0.0:\n",
      "      Successfully uninstalled torch-2.0.0\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.15.1\n",
      "    Uninstalling torchvision-0.15.1:\n",
      "      Successfully uninstalled torchvision-0.15.1\n",
      "Successfully installed torch-2.1.0 torchvision-0.16.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers --upgrade\n",
    "!pip install gradio --upgrade\n",
    "!pip install torch torchvision --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21369ff",
   "metadata": {},
   "source": [
    "#### Hello world in gradio\n",
    "\n",
    "As a tradition, let us build the simplest `gradio` app. It accepts a `text` input and calls the `greet()` function to process this input and convert into another text. The output of `greet()` becomes the output of the `gradio` app.\n",
    "\n",
    "To see our application, we call `launch()` after constructing our `gradio` `Interface`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c2c37a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7868\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7868/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def greet(name):\n",
    "    return \"Hello \" + name + \"!!\"\n",
    "\n",
    "gr.Interface(fn=greet, inputs=\"text\", outputs=\"text\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74361507",
   "metadata": {},
   "source": [
    "#### Object Recognition using ResNet18\n",
    "\n",
    "In our discussion about PyTorch, we used a pre-trained ResNet18 model from `torchvision`. We use `jupyter` notebook to show the results. The `jupyter` notebook is not an application that we can deploy and other people use with ease. The same with Google's colab. \n",
    "\n",
    "In this example, we use `gradio` to build a simple app that an end user can easily interact with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d73061fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7869\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7869/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import torch \n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import requests\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "resnet = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "resnet.eval()\n",
    "\n",
    "# Download human-readable labels for ImageNet.\n",
    "response = requests.get(\"https://git.io/JJkYN\")\n",
    "labels = response.text.split(\"\\n\")\n",
    "\n",
    "def classify(img):\n",
    "    # By default, gradio image is numpy\n",
    "    img = torch.from_numpy(img)\n",
    "    # Numpy image is channel last. PyTorch is channel 1st.\n",
    "    img = img.permute(2, 0, 1)\n",
    "    \n",
    "    # The transforms before prediction\n",
    "    img = torchvision.transforms.Resize(256, antialias=True)(img)\n",
    "    img = torchvision.transforms.CenterCrop(224)(img).float()/255.\n",
    "    img = normalize(img)\n",
    "    \n",
    "    # We insert batch size of 1\n",
    "    img = img.unsqueeze(0)\n",
    "    \n",
    "    # The actual prediction\n",
    "    with torch.no_grad():\n",
    "        pred = resnet(img)\n",
    "    \n",
    "    # Convert the prediction to probabilities\n",
    "    pred = torch.nn.functional.softmax(pred, dim=1)\n",
    "    # Remove the batch dim. torch.squeeze() can also be used.\n",
    "    pred = pred.squeeze()\n",
    "    \n",
    "    # torch to numpy space\n",
    "    pred = pred.cpu().numpy()\n",
    "    \n",
    "    return {labels[i]: float(pred[i]) for i in range(1000)}\n",
    "    \n",
    "\n",
    "gr.Interface(fn=classify, \n",
    "             inputs=gr.Image(shape=(224, 224)),\n",
    "             outputs=gr.Label(num_top_classes=5),\n",
    "             title=\"1k Object Recognition\",\n",
    "             examples=['assets/wonder_cat.jpg', 'assets/aki_dog.jpg','assets/birdie1.jpg'],\n",
    "             description=\"Demonstrates a pre-trained model from torchvision for image classification.\",\n",
    "             allow_flagging=\"never\").launch(inbrowser=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea09cf26",
   "metadata": {},
   "source": [
    "#### Using HuggingFace and Gradio\n",
    "\n",
    "Loading a pre-trained model from torchvision, pre-processing the input, and post processing the output are all messy. Sometimes, we just want to load and use a machine learning model. Hugging Face provides a shortcut for all these steps through the use of `pipeline`. In `pipeline`, we supply the task name and the pre-trained model that is stored in Hugging Face Model Hub.\n",
    "\n",
    "In this example, we use a much better model compared to ResNet18. It is called [BEIT](https://arxiv.org/abs/2106.08254) and can classify objects up to about 22k categories. We construct the `gradio` app by calling `from_pipeline()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "510928fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7870\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7870/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(task=\"image-classification\", \n",
    "                 # model that can do 22k-category classification\n",
    "                 model=\"microsoft/beit-base-patch16-224-pt22k-ft22k\")\n",
    "gr.Interface.from_pipeline(pipe, \n",
    "                           title=\"22k Image Classification\",\n",
    "                           description=\"Object Recognition using Microsoft BEIT\",\n",
    "                           examples = ['assets/wonder_cat.jpg', 'assets/aki_dog.jpg','assets/birdie1.jpg'],\n",
    "                           allow_flagging=\"never\").launch(inbrowser=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb86c1b6",
   "metadata": {},
   "source": [
    "#### Automatic Speech Recognition (ASR)\n",
    "\n",
    "Let us shift to audio or speech domain. In this example, we demonstrate an Automatic Speech Recognition (ASR) system. We will use our microphone to record audio which is then converted to text using ASR. In this example, best to open the application in another browser tab by setting `inbrowser=True`.\n",
    "\n",
    "Before running the `gradio` app, this ASR requires `sentencepice` module. Let us install it first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d73f6123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in /Users/rowel/anaconda3/envs/llm/lib/python3.10/site-packages (0.1.97)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ad04d0",
   "metadata": {},
   "source": [
    "In this ASR, we use OpenAI Whisper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66d394c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7871\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7871/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rowel/anaconda3/envs/speech/lib/python3.10/site-packages/gradio/processing_utils.py:188: UserWarning: Trying to convert audio automatically from int32 to 16-bit int format.\n",
      "  warnings.warn(warning.format(data.dtype))\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(task=\"automatic-speech-recognition\", \n",
    "                model=\"openai/whisper-tiny\")\n",
    "gr.Interface.from_pipeline(pipe,\n",
    "                           title=\"Automatic Speech Recognition (ASR)\",\n",
    "                           description=\"Using pipeline with OpenAI Whisper\",\n",
    "                           examples=['assets/ljspeech.wav',],\n",
    "                           ).launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cfb3b5",
   "metadata": {},
   "source": [
    "#### Text to Speech (TTS)\n",
    "\n",
    "Let us do the reverse of ASR or Text to Speech (TTS). In this example, we supply text and this text is converted to speech using the voice of Linda Johnson. We use a pre-trained model of [FastSpeech2](https://arxiv.org/abs/2006.04558) that is provided by Facebook in Model Hub.\n",
    "\n",
    "In this example, we use [`load()`](https://gradio.app/docs/#load) method to load the pre-trained model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "276b27ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching model from: https://huggingface.co/facebook/fastspeech2-en-ljspeech\n",
      "Running on local URL:  http://127.0.0.1:7872\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7872/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "gr.load(\"huggingface/facebook/fastspeech2-en-ljspeech\", \n",
    "        description=\"TTS using FastSpeech2\",\n",
    "        title=\"Text to Speech (TTS)\",\n",
    "        examples=[[\"The quick brown fox jumps over the lazy dog.\"]]\n",
    "        ).launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
