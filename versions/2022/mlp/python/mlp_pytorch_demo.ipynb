{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP for CIFAR10\n",
    "\n",
    "Multi-Layer Perceptron (MLP) is a simple neural network model that can be used for classification tasks. \n",
    "\n",
    "In this demo, we will train a 3-layer MLP on the CIFAR10 dataset. We will illustrate 2 MLP implementations.\n",
    "\n",
    "Let us first import the required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-24 15:14:08.101961: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import wandb\n",
    "import math\n",
    "from torch import nn\n",
    "from einops import rearrange\n",
    "from argparse import ArgumentParser\n",
    "from pytorch_lightning import LightningModule, Trainer, Callback\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from torchmetrics.functional import accuracy\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP using PyTorch `nn.Linear`\n",
    "\n",
    "The most straightforward way to implement an MLP is to use the `nn.Linear` module. In the following code, we implement a 3-layer MLP with GELU activation function. The GELU can be replaced by other activation functions such as RELU.\n",
    "\n",
    "Pls take note of the correct sizes. `fc1` input size is `n_features` which is size of the flattened input `x`. `fc1` output size is `n_hidden` which then becomes the input size of `fc2`. In other words, all input/output sizes up to `fc3` fit together perfectly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, n_features=3*32*32, n_hidden=512, num_classes=10):\n",
    "        super().__init__()\n",
    "        # the 3 Linear layers of the MLP\n",
    "        self.fc1 = nn.Linear(n_features, n_hidden)\n",
    "        self.fc2 = nn.Linear(n_hidden, n_hidden)\n",
    "        self.fc3 = nn.Linear(n_hidden, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # flatten x - (batch_size, 3, 32, 32) -> (batch_size, 3*32*32)\n",
    "        # ascii art for the case that x is 1 x 2 x 2 (channel, height, width)\n",
    "        # ---------         ----------------- \n",
    "        # | 1 | 2 |    ---> | 1 | 2 | 3 | 4 |\n",
    "        # | 3 | 4 |         -----------------\n",
    "        # ---------\n",
    "        # we can use any of the following methods to flatten the tensor\n",
    "        #y = torch.flatten(x, 1)\n",
    "        #y = x.view(x.size(0), -1)\n",
    "        # but this is the most intuitive since it shows the actual flattening\n",
    "        y = rearrange(x, 'b c h w -> b (c h w)')\n",
    "        y = nn.GELU()(self.fc1(y))\n",
    "        y = nn.GELU()(self.fc2(y))\n",
    "        y = self.fc3(y)\n",
    "        return y\n",
    "        # we dont need to compute softmax since it is already\n",
    "        # built into the CE loss function in PyTorch\n",
    "        #return F.log_softmax(y, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP implementation using Tensors\n",
    "\n",
    "In this case, we illustrate how to implement the formula of an MLP layer using weights and biases. Note that if we remove the initialization of the weights and biases, the model will not converge. In the previous example, `Linear` automatically performs the weights and biases initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorMLP(nn.Module):\n",
    "    def __init__(self, n_features=3*32*32, n_hidden=512, num_classes=10):\n",
    "        super().__init__()\n",
    "\n",
    "        # weights and biases for layer 1\n",
    "        self.w1 = nn.Parameter(torch.empty((n_hidden, n_features)))\n",
    "        self.b1 = nn.Parameter(torch.empty((n_hidden,)))\n",
    "\n",
    "         # weights and biases for layer 2\n",
    "        self.w2 = nn.Parameter(torch.empty((n_hidden, n_hidden)))\n",
    "        self.b2 = nn.Parameter(torch.empty((n_hidden,)))\n",
    "\n",
    "         # weights and biases for layer 3\n",
    "        self.w3 = nn.Parameter(torch.empty((num_classes, n_hidden)))\n",
    "        self.b3 = nn.Parameter(torch.empty((num_classes,)))\n",
    "\n",
    "        # initialize parameters manually bec we implemented the linear layer manually\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        # we use Kaiming initializer for weights\n",
    "        nn.init.kaiming_uniform_(self.w1, a=math.sqrt(5))\n",
    "        # zero for biases\n",
    "        nn.init.constant_(self.b1, 0)\n",
    "        nn.init.kaiming_uniform_(self.w2, a=math.sqrt(5))\n",
    "        nn.init.constant_(self.b2, 0)\n",
    "        nn.init.kaiming_uniform_(self.w3, a=math.sqrt(5))\n",
    "        nn.init.constant_(self.b3, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # flatten\n",
    "        y = rearrange(x, 'b c h w -> b (c h w)')\n",
    "        # we manually compute the output of each layer\n",
    "        y = y @ self.w1.T + self.b1\n",
    "        y = nn.GELU()(y)\n",
    "        y = y @ self.w2.T + self.b2\n",
    "        y = nn.GELU()(y)\n",
    "        y = y @ self.w3.T + self.b3\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PyTorch Lightning Module for MLP\n",
    "\n",
    "This is the PL module so we can easily change the implementation of the MLP and compare the results.  More detailed results can be found on the `wandb.ai` page.\n",
    "\n",
    "Using `model` parameter, we can easily switch between the two MLP implementations shown above. We also benchmark the result using a ResNet18 model. The rest of the code is similar to our PL module example for MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitCIFAR10Model(LightningModule):\n",
    "    def __init__(self, num_classes=10, lr=0.001, batch_size=64,\n",
    "                 num_workers=4, max_epochs=30,\n",
    "                 model=SimpleMLP):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.model = model(num_classes=num_classes)\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    # this is called during fit()\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = self.loss(y_hat, y)\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    # calls to self.log() are recorded in wandb\n",
    "    def training_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x[\"loss\"] for x in outputs]).mean()\n",
    "        self.log(\"train_loss\", avg_loss, on_epoch=True)\n",
    "\n",
    "    # this is called at the end of an epoch\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = self.loss(y_hat, y)\n",
    "        acc = accuracy(y_hat, y) * 100.\n",
    "        # we use y_hat to display predictions during callback\n",
    "        return {\"y_hat\": y_hat, \"test_loss\": loss, \"test_acc\": acc}\n",
    "\n",
    "    # this is called at the end of all epochs\n",
    "    def test_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x[\"test_loss\"] for x in outputs]).mean()\n",
    "        avg_acc = torch.stack([x[\"test_acc\"] for x in outputs]).mean()\n",
    "        self.log(\"test_loss\", avg_loss, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"test_acc\", avg_acc, on_epoch=True, prog_bar=True)\n",
    "\n",
    "    # validation is the same as test\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "       return self.test_step(batch, batch_idx)\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        return self.test_epoch_end(outputs)\n",
    "\n",
    "    # we use Adam optimizer\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = Adam(self.parameters(), lr=self.hparams.lr)\n",
    "        # this decays the learning rate to 0 after max_epochs using cosine annealing\n",
    "        scheduler = CosineAnnealingLR(optimizer, T_max=self.hparams.max_epochs)\n",
    "        return [optimizer], [scheduler]\n",
    "    \n",
    "    # this is called after model instatiation to initiliaze the datasets and dataloaders\n",
    "    def setup(self, stage=None):\n",
    "        self.train_dataloader()\n",
    "        self.test_dataloader()\n",
    "\n",
    "    # build train and test dataloaders using MNIST dataset\n",
    "    # we use simple ToTensor transform\n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            torchvision.datasets.CIFAR10(\n",
    "                \"./data\", train=True, download=True, \n",
    "                transform=torchvision.transforms.ToTensor()\n",
    "            ),\n",
    "            batch_size=self.hparams.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.hparams.num_workers,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            torchvision.datasets.CIFAR10(\n",
    "                \"./data\", train=False, download=True, \n",
    "                transform=torchvision.transforms.ToTensor()\n",
    "            ),\n",
    "            batch_size=self.hparams.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.hparams.num_workers,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self.test_dataloader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Arguments\n",
    "\n",
    "Please change the `--model` argument to switch between the different models to be used as CIFAR10 classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args():\n",
    "    parser = ArgumentParser(description=\"PyTorch Lightning MNIST Example\")\n",
    "    parser.add_argument(\"--max-epochs\", type=int, default=30, help=\"num epochs\")\n",
    "    parser.add_argument(\"--batch-size\", type=int, default=64, help=\"batch size\")\n",
    "    parser.add_argument(\"--lr\", type=float, default=0.001, help=\"learning rate\")\n",
    "\n",
    "    parser.add_argument(\"--num-classes\", type=int, default=10, help=\"num classes\")\n",
    "\n",
    "    parser.add_argument(\"--devices\", default=1)\n",
    "    parser.add_argument(\"--accelerator\", default='gpu')\n",
    "    parser.add_argument(\"--num-workers\", type=int, default=4, help=\"num workers\")\n",
    "    \n",
    "    #parser.add_argument(\"--model\", default=torchvision.models.resnet18)\n",
    "    #parser.add_argument(\"--model\", default=TensorMLP)\n",
    "    parser.add_argument(\"--model\", default=SimpleMLP)\n",
    "    args = parser.parse_args(\"\")\n",
    "    return args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weights and Biases Callback\n",
    "\n",
    "The callback logs train and validation metrics to `wandb`. It also logs sample predictions. This is similar to our `WandbCallback` example for MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WandbCallback(Callback):\n",
    "\n",
    "    def on_validation_batch_end(self, trainer, pl_module, outputs, batch, batch_idx, dataloader_idx):\n",
    "        # process first 10 images of the first batch\n",
    "        if batch_idx == 0:\n",
    "            label_human = [\"airplane\", \"automobile\", \"bird\", \"cat\",\n",
    "                           \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "            n = 10\n",
    "            x, y = batch\n",
    "            outputs = outputs[\"y_hat\"]\n",
    "            outputs = torch.argmax(outputs, dim=1)\n",
    "            # log image, ground truth and prediction on wandb table\n",
    "            columns = ['image', 'ground truth', 'prediction']\n",
    "            data = [[wandb.Image(x_i), label_human[y_i], label_human[y_pred]] for x_i, y_i, y_pred in list(\n",
    "                zip(x[:n], y[:n], outputs[:n]))]\n",
    "            wandb_logger.log_table(\n",
    "                key=pl_module.model.__class__.__name__,\n",
    "                columns=columns,\n",
    "                data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and Validation of Different Models\n",
    "\n",
    "The validation accuracy of both MLP model implmentations are almost the same at `~53%`. This shows that the 2 MLP implementations are almost the same.\n",
    "\n",
    "Meanwhile the ResNet18 model has accuracy of `~78%`. The MLP model has still a long way to go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "LitCIFAR10Model(\n",
      "  (model): SimpleMLP(\n",
      "    (fc1): Linear(in_features=3072, out_features=512, bias=True)\n",
      "    (fc2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (fc3): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      "  (loss): CrossEntropyLoss()\n",
      ")\n",
      "SimpleMLP\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    args = get_args()\n",
    "    model = LitCIFAR10Model(num_classes=args.num_classes,\n",
    "                           lr=args.lr, batch_size=args.batch_size,\n",
    "                           num_workers=args.num_workers,\n",
    "                           model=args.model,)\n",
    "    model.setup()\n",
    "\n",
    "    # printing the model is useful for debugging\n",
    "    print(model)\n",
    "    print(model.model.__class__.__name__)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/rowel/github/roatienza/Deep-Learning-Experiments/versions/2022/mlp/python/wandb/run-20220422_203035-24btlkes</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/rowel/mlp-cifar/runs/24btlkes\" target=\"_blank\">azure-donkey-9</a></strong> to <a href=\"https://wandb.ai/rowel/mlp-cifar\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name  | Type             | Params\n",
      "-------------------------------------------\n",
      "0 | model | SimpleMLP        | 1.8 M \n",
      "1 | loss  | CrossEntropyLoss | 0     \n",
      "-------------------------------------------\n",
      "1.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 M     Total params\n",
      "7.365     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70d76e883fbe41c69bddea42a3600105",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afea7980902e426492aa06270be86a6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00339e5419bb4fdfae92115acb961f1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rowel/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py:1403: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  \" and \".join(warn_msg) + \" are deprecated. nn.Module.state_dict will not accept them in the future. \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c66ed0282d4948839c65eb26c743d7c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d9bc2b8fa4047ce90f724133e79caa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15b6da87a15240148e722a40c7c63cfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "055dab92abe147ceaf0dba37e3297f6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b8306d67ac447cc9cd1e2cbdc322194",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a228b08547794153ac6b11d0e4229eb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32fdc5391782497db4076cf97969cb2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6991845f99842b7a99f10e48453d989",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1940b4b8d54f491a84ea86356481a8c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0e03ce4a9434de7b037704d28b010fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "050581f68e1b417caa8130d2cfc17505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "963d5abe65184fae9a5893faf30d53ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1418255d83304e79833fe061a89520a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b72feee6dc8b46b8bd8d071629ffffa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f7807f054bc44c0992aa160b84f62ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "380b44d3209d411093da32ace4eca2b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1a053dbc40f498db55c2d4c37df0482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dba6d20d81e2422395d6e6e24c7a33c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a3e931f0bf74bafb19bcc246dd383e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08a92a518a9b4ffa9f264a66255c6fde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b28dd1192a9e4cb49f3591ff99c87dda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f2cd04fd1f848638ed8282ac775c611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c5ee40518dd4b85bb908897f215b872",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2d87d7199414741983b6017b44adc52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e59cb0a85d34d5a98f506c8aa135946",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42f98e2a3ce3426c9ec1d42678a1e26c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46a5e4cb3de049c189a04ecc2ca1bde8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d454bcb11f4441f8303f8977c41d6a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f63a5d1c63cb40138544992374b9eb12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e517446e0b7341ea84d00af2549cb832",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc             54.03065490722656\n",
      "        test_loss           1.4564441442489624\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a59a687db6bf4e26973f1d572368290f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.164 MB of 0.164 MB uploaded (0.023 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B sync reduced upload amount by 8.2%             "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>test_acc</td><td>▁▃▃▄▅▆▆▆▆▇▆▇▇▇▇▇▇█▇▇███████████</td></tr><tr><td>test_loss</td><td>█▆▅▄▂▂▂▂▂▁▁▂▁▁▁▂▂▂▂▂▂▃▂▃▃▃▃▃▃▃▃</td></tr><tr><td>train_loss</td><td>█▇▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>test_acc</td><td>54.03065</td></tr><tr><td>test_loss</td><td>1.45644</td></tr><tr><td>train_loss</td><td>0.76653</td></tr><tr><td>trainer/global_step</td><td>23460</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">azure-donkey-9</strong>: <a href=\"https://wandb.ai/rowel/mlp-cifar/runs/24btlkes\" target=\"_blank\">https://wandb.ai/rowel/mlp-cifar/runs/24btlkes</a><br/>Synced 7 W&B file(s), 31 media file(s), 32 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220422_203035-24btlkes/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "    # wandb is a great way to debug and visualize this model\n",
    "    wandb_logger = WandbLogger(project=\"mlp-cifar\")\n",
    "    \n",
    "    trainer = Trainer(accelerator=args.accelerator,\n",
    "                      devices=args.devices,\n",
    "                      max_epochs=args.max_epochs,\n",
    "                      logger=wandb_logger,\n",
    "                      callbacks=[WandbCallback()])\n",
    "    trainer.fit(model)\n",
    "    trainer.test(model)\n",
    "\n",
    "    wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "52772734322c44a04e342c358be70f2ff4d97da358cb3cd38ceb0f6066598be5"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
